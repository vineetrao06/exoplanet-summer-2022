{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb8a09d",
   "metadata": {},
   "source": [
    "# Exoplanet Summer 2022\n",
    "## Abstract\n",
    "The search for habitable exoplanets has been the purpose for our research this semester. Considering that there are thousands of exoplanets in the universe, we believe that there must be at least one that possesses the characteristics needed to support basic life - the capability to hold liquid water. The most important question, therefore, is: can a given exoplanet support liquid or molecular water? Whether or not this is possible depends on a multitude of characteristics unique to each exoplanet, including planetary radius, orbital period, stellar radius, and planetary mass, which work together to create an environment capable of life. The purpose of our research in Summer 2022 was to unravel this “mystery” by looking at data values from the NASA Exoplanet Archive (Planetary Systems Dataset). We started with a Python program to find and remove duplicate entries in the NASA Exoplanet Archives. We then analyzed multiple planetary and stellar data values through the analysis of luminosity and absolute magnitude to filter out a list for us to take a deep dive into. Subsequently, we conducted statistical calculations for further analysis. Further efforts were made by applying Albedo and Circumstellar Habitable Zone (CHZ) data to the analysis of the habitability of an exoplanet. In the end, we formulated a list of ten exoplanets that we believe to be capable of supporting life.\n",
    "\n",
    "## Background\n",
    "The purpose behind our search for exoplanets is to reveal the possibilities of life beyond earth. We have always looked at the cosmos as a dark and inhabitable vacuum, but the chances of Earth being the only planet with life in this universe are slim. All creatures look up to the sky, but the ability to question what is there is what makes the human species different from others. And the ability to persevere to answer this question has gotten us where we are. So far, we have been able to prove that Mars has very similar characteristics to Earth through robotic missions, and we are continuing to make new discoveries not only about Mars's geological history, but how we evolved as well. This knowledge will only be furthered by expanding beyond our solar system. Ever since the first ever exoplanet was discovered in 1992, there have been over 35,000 more exoplanets that have been confirmed to be present outside our solar system. We will deepen our understanding of our purpose as a planet, and be able to realize how significant we are. There are other benefits as well, such as the infinite resources space has to offer, and the reassurance that we can become an interplanetary species, but in this paper, we simply focus on addressing the first challenge: detecting exoplanets. \n",
    "\n",
    "## Search for habitability\n",
    "During the hunt for potentially habitable exoplanets, we looked through the NASA Exoplanet Archive, searching for the qualities that would determine if a specific planet could be inhabited by humans. Since our goal was to identify exoplanets that can support life, we considered how to best succeed at this objective. We learned that the simplest method of beginning to check if a planet could support life is to find out whether or not the said planet can hold liquid water. This is because water, in its liquid form, has a number of characteristics that make it necessary for life. It can cause adhesion and cohesion, can dissolve more substances than any other liquid, and is able to withstand large changes in temperature. Although no dataset contains information about liquid water itself, we utilized various techniques to discover more about the exoplanets and their capability to sustain the “universal solvent.” One of these methods is deduping the dataset; this involves removing the duplicates of each planet with multiple entries in the set and thus making the data clearer. Another useful technique is Keplerian Mechanics, in which we define a certain planet to be habitable if other celestial bodies that are similar to the exoplanet in question (e.g. Earth and K2-18 b) are. The most important method we implemented this Fall is the five-number summary. Including statistics in our research greatly increased our productivity. Additionally, we tried to use other methods such as habitable zone calculations and albedo. Our result was a list of ten exoplanets whose characteristics matched those of Earth and K2-18 b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dff0ee1",
   "metadata": {},
   "source": [
    "## Filtering Process"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b9d9af6",
   "metadata": {},
   "source": [
    "In our Filtering process, we have two different type of analysis: removal of duplicate entries and the elimination of planets with controversial flags of 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd631449",
   "metadata": {},
   "source": [
    "### Removal of controversial flags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f408d",
   "metadata": {},
   "source": [
    "After wiping out entries of duplicate exoplanets with  outdated publication dates, we ventured to further our process of elimination by removing entries with a controversial flag of 1. Controversial flags are denoted by the term pl_controv_flag, by which they are represented in boolean values of either 0 or 1. When an exoplanet has a controversial flag of 0, then it is considered to be a confirmed planet, making it a potential contender for being capable of sustaining human life. However, if an exoplanet has a controversial flag of 1, then its existence has been questioned in the past - making it not completely confirmed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77162c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('../data/dataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e13d10",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'controv_flags_col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[\u001b[43mcontrov_flags_col\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'controv_flags_col' is not defined"
     ]
    }
   ],
   "source": [
    "df = df.loc[controv_flags_col != 1]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe99ebd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"New size of dataset: \" + str(len(df)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aac8e4d",
   "metadata": {},
   "source": [
    "### Deduplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd9d8e7",
   "metadata": {},
   "source": [
    "The NASA Exoplanet Archive has over 35,000 entries as of July 2022, consisting of duplicate values for the majority of planets listed. Thus, to eliminate the various duplicate entries, we initially read the dataset as a Pandas dataframe via the Pandas module in Python. After, we arranged all the entries based on the publication date of each planet in ascending order - which can be denoted as disc_pubdate. The sorting of data was crucial to preserving the most recent and accurate finding for each exoplanet, as we only intend on keeping the last occurrence of a particular exoplanet, since it is assumed to be the most up-to-date. The removal of duplicate entries in NASA’s Exoplanet Archive successfully narrows down 35,000 entries to simply 5,055 exoplanets. Thus, it yields an elimination of almost 30,000 planets standalone - making it a vital process when performing our analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving for later, where we will get to elimination process\n",
    "planet_names = df[\"pl_name\"]\n",
    "controv_flags_col = df['pl_controv_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_count = planet_names.value_counts()\n",
    "duplicate_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c32491",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('disc_pubdate', ascending=True)\n",
    "\n",
    "df = df.drop_duplicates(subset=['pl_name'], keep='last')\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c95496",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"New size of dataset: \" + str(len(df)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60880a75",
   "metadata": {},
   "source": [
    "## CHZ Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b9f61",
   "metadata": {},
   "source": [
    "Through our CHZ process, we eliminate all the planets that are not within our circumstellar habitable zone. Amid our process, we consider various factors such as the stellar type, planetary luminosity, bolometric lumniocity, absolute magnitude, semi minor/major axis, and more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35aac65",
   "metadata": {},
   "source": [
    "### Luminosity and absolute magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cf4530",
   "metadata": {},
   "source": [
    "After de-duplicating the dataset and removing planets with controversial flags, we were ready to perform the CHZ calculations. The stellar luminosity was the core of these calculations because it was needed to determine the inner and outer bounds of the CHZ. \n",
    "\n",
    "The values for stellar luminosity in the dataset were represented as logarithms of their actual values, so if there was a value for the luminosity of the host star of an exoplanet, we had to raise 10 to the power of that value to determine the host star’s luminosity (in solar luminosities), as shown in Figure 1.\n",
    "\n",
    "While performing this calculation, we found that many planets had null values for their host star’s luminosity. Therefore, we used the Stefan-Boltzmann law to calculate the luminosity of a host star if it did not already have a value for its luminosity. However, the Stefan-Boltzmann law required values for stellar radius and stellar temperature, so if a host star’s luminosity and at least one of its radius and temperature values were null, there was no possible way to determine its luminosity. There were 594 exoplanets for which the aforementioned conditions were true, so we had to remove them from the dataset. However, this does not mean that the removed exoplanets are not habitable; we simply could not determine their habitability because they were missing too many values in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48364f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(df)):\n",
    "\n",
    "    # The values for luminosity in the dataset are represented as logs, so\n",
    "    # if there is a value, the actual luminosity (in solar luminosities)\n",
    "    # is 10 to the power of that value\n",
    "\n",
    "    if pd.notna(df['st_lum'][i]):\n",
    "        df['st_lum'][i] = 10**(df['st_lum'][i])\n",
    "\n",
    "    # If there's not a luminosity value, but there are stellar radius and\n",
    "    # temperature values, the luminosity can be calculated using the\n",
    "    # Stefan-Boltzmann law, with all untis in terms of the Sun's physical\n",
    "    # parameters (the Sun's temperature is 5778 K and the stellar radius is\n",
    "    # already in terms of the Sun's radius)\n",
    "\n",
    "    if ((pd.isna(df['st_lum'][i])) & ((pd.notna(df['st_teff'][i])) & (pd.notna(df['st_rad'][i])))):\n",
    "        df['st_lum'][i] = (df['st_rad'][i]**2) * ((df['st_teff'][i]/5778)**4)\n",
    "\n",
    "    # Otherwise, at least the luminosity and at least one of the stellar radius\n",
    "    # and stellar temperature are missing, so it is impossible to calculate\n",
    "    # the star's luminosity\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# After the luminosity calculations have been performed,\n",
    "# planets with no values for their star's luminosity must be removed\n",
    "\n",
    "df = df.loc[pd.notna(df['st_lum'])]\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Creating a new column for absolute magnitude, based on the relation\n",
    "# between absolute magnitude and luminosity (see Wikipedia page)\n",
    "\n",
    "df['st_abs_mag'] = 4.74 + (-2.5*np.log10(df['st_lum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580bebd1",
   "metadata": {},
   "source": [
    "### Calculation of Bolometric Magnitude and Luminosity Based on Stellar Temperature / Spectral Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fadc0c",
   "metadata": {},
   "source": [
    "The inner and outer bounds of the CHZ depend on the bolometric luminosity, not just standard stellar luminosity. Bolometric luminosity is a star’s luminosity across all wavelengths, as opposed to a star’s luminosity when viewed in a particular band. The definition for bolometric magnitude follows similarly. The absolute magnitude of each star determined above was the visual absolute magnitude. To determine the bolometric magnitude and then the bolometric luminosity, a bolometric correction must be added to the visual absolute magnitude. The bolometric correction depends on a star’s spectral class (or temperature). Once we determined the bolometric magnitude for each host star, we were able to calculate the bolometric luminosity of each host star using a rearranged form of Equation 1, as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['st_spectype'] = df['st_spectype'].astype(str)\n",
    "\n",
    "df['bol_mag'] = 0\n",
    "\n",
    "# The for loop below adds a bolometric magnitude for the host star of each planet\n",
    "# BC is the bolometric correction, which is used to convert from absolute magnitude\n",
    "# (st_abs_mag) to bolometric magnitude\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    BC = 0\n",
    "    if (df['st_teff'][i] >= 2400 and df['st_teff'][i] <= 3700) or df['st_spectype'][i][0] == 'M':\n",
    "        BC = -2.0\n",
    "    elif (df['st_teff'][i] >= 3700 and df['st_teff'][i] <= 5200) or df['st_spectype'][i][0] == 'K':\n",
    "        BC = -0.8\n",
    "    elif (df['st_teff'][i] >= 5200 and df['st_teff'][i] <= 6000) or df['st_spectype'][i][0] == 'G':\n",
    "        BC = -0.4\n",
    "    elif (df['st_teff'][i] >= 6000 and df['st_teff'][i] <= 7500) or df['st_spectype'][i][0] == 'F':\n",
    "        BC = -0.15\n",
    "    elif (df['st_teff'][i] >= 7500 and df['st_teff'][i] <= 10000) or df['st_spectype'][i][0] == 'A':\n",
    "        BC = -0.3\n",
    "    elif (df['st_teff'][i] >= 10000 and df['st_teff'][i] <= 30000) or df['st_spectype'][i][0] == 'B':\n",
    "        BC = -2.0\n",
    "    df['bol_mag'][i] = df['st_abs_mag'][i] + BC\n",
    "\n",
    "# Creating a new column for BOLOMETRIC luminosity, based on BOLOMETRIC Magnitude\n",
    "# (This is different from st_lum and st_abs_mag)\n",
    "# The bolometric luminosity must be used for the CHZ calculations\n",
    "# Once again, this formula can be found on Wikipedia\n",
    "\n",
    "df['bol_lum'] = 10**((df['bol_mag']-4.74)/-2.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3841364d",
   "metadata": {},
   "source": [
    "### Determining habitability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d20075e",
   "metadata": {},
   "source": [
    "Once we calculated the bolometric luminosity for each host star, we were able to determine the inner and outer bounds of the CHZ, in AU, for each host star using Equations 2 and 3 below (taken from Tom Morris’s paper). \n",
    "\n",
    "We then checked if the exoplanet’s average orbiting distance around its host star was within the CHZ bounds of its host star. The average orbiting distance is dependent on the eccentricity of the orbit; if the eccentricity is small, the semi-major axis is a good approximation of the average orbiting distance, but if the eccentricity is large, the approximation breaks down. We decided that if the eccentricity of an exoplanet’s orbit was less than or equal to 0.2, the semi-major axis would be a good approximation of the exoplanet’s average orbiting distance. If the eccentricity was greater than 0.2, we used Equation 3 for the average orbiting distance, in which dₐᵥ is the mean distance averaged over time, a is the semi-major axis, and e is the eccentricity. If there was no value for the semi-major axis of a planet’s orbit, but there was a value for its orbital period, we used Kepler’s 3rd Law (Equation 5) to determine the semi-major axis, where T was the orbital period in years, a was the semi-major axis in AU, and M was the mass of the host star in solar masses. If the average orbiting distance of an exoplanet was within the CHZ bounds of its host star, we considered it to be habitable. If the eccentricity value for an exoplanet was null or the values for its semi-major axis, orbital period, and host star’s mass were null, we could not determine the habitability of the exoplanet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ecda92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the inner boundary of the CHZ (formula from Tom Morris)\n",
    "\n",
    "df['inner_CHZ'] = np.sqrt(df['bol_lum']/1.1)\n",
    "\n",
    "# Defining the outer boundary of the CHZ (formula from Tom Morris)\n",
    "\n",
    "df['outer_CHZ'] = np.sqrt(df['bol_lum']/0.53)\n",
    "\n",
    "# Creating a new column to determine if planets are habitable\n",
    "\n",
    "df['Habitable'] = None\n",
    "\n",
    "planets = []\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "\n",
    "    # First if statement checks if there are values for the planet's\n",
    "    # semi-major axis and eccentricity\n",
    "\n",
    "    if ((pd.notna(df['pl_orbsmax'][i])) & (pd.notna(df['pl_orbeccen'][i]))):\n",
    "\n",
    "        # If the eccentricity is less than 0.2, the average distance from the planet\n",
    "        # to its star can be approximated by its semi-major axis\n",
    "        # If the average distance is in the CHZ range, we say the planet is\n",
    "        # habitable\n",
    "\n",
    "        if df['pl_orbeccen'][i] <= 0.2:\n",
    "            if ((df['pl_orbsmax'][i] >= df['inner_CHZ'][i]) & (df['pl_orbsmax'][i] <= df['outer_CHZ'][i])):\n",
    "                df['Habitable'][i] = 'Yes'\n",
    "                planets.append(df['pl_name'][i])\n",
    "            else:\n",
    "                df['Habitable'][i] = 'No'\n",
    "\n",
    "        # If the eccentricity is greater than 0.2, we must use a formula for\n",
    "        # the average distance. TODO: CITE SOURCE!! . and then check if this\n",
    "        # average distance is in the CHZ range\n",
    "\n",
    "        else:\n",
    "            avg_dist = df['pl_orbsmax'][i] * (1+((df['pl_orbeccen'][i]**2)/2))\n",
    "            if ((avg_dist >= df['inner_CHZ'][i]) & (avg_dist <= df['outer_CHZ'][i])):\n",
    "                df['Habitable'][i] = 'Yes'\n",
    "                planets.append(df['pl_name'][i])\n",
    "            else:\n",
    "                df['Habitable'][i] = 'No'\n",
    "\n",
    "    # If there is no value for the planet's semi-major axis, but there are values\n",
    "    # for its orbital period, eccentricity, and the star's mass, we can use\n",
    "    # Kepler's 3rd Law to calculate its semi-major axis, and then perform\n",
    "    # the eccentricity check again to determine the average orbiting distance\n",
    "    # and then determine if this average distance is in the CHZ\n",
    "\n",
    "    elif ((pd.isna(df['pl_orbsmax'][i])) & (pd.notna(df['pl_orbeccen'][i])) & (pd.notna(df['pl_orbper'][i])) & (pd.notna(df['st_mass'][i]))):\n",
    "\n",
    "        # Convering the orbital period from days to years\n",
    "\n",
    "        orb_per_year = df['pl_orbper'][i]/365\n",
    "\n",
    "        # Using Kepler's Third Law: T^2/a^3 = 1/M, with T in years, a in AU\n",
    "        # and M in solar masses, so a = cubert(T^2 * M)\n",
    "\n",
    "        df['pl_orbsmax'][i] = np.cbrt((orb_per_year**2)*df['st_mass'][i])\n",
    "\n",
    "        if df['pl_orbeccen'][i] <= 0.2:\n",
    "            if ((df['pl_orbsmax'][i] >= df['inner_CHZ'][i]) & (df['pl_orbsmax'][i] <= df['outer_CHZ'][i])):\n",
    "                df['Habitable'][i] = 'Yes'\n",
    "                planets.append(df['pl_name'][i])\n",
    "            else:\n",
    "                df['Habitable'][i] = 'No'\n",
    "\n",
    "        else:\n",
    "            avg_dist = df['pl_orbsmax'][i] * (1+((df['pl_orbeccen'][i]**2)/2))\n",
    "            if ((avg_dist >= df['inner_CHZ'][i]) & (avg_dist <= df['outer_CHZ'][i])):\n",
    "                df['Habitable'][i] = 'Yes'\n",
    "                planets.append(df['pl_name'][i])\n",
    "            else:\n",
    "                df['Habitable'][i] = 'No'\n",
    "\n",
    "    # Otherwise, there are too many values missing to determine if the planet\n",
    "    # is habitable. CND = Can Not Determine\n",
    "\n",
    "    else:\n",
    "        df['Habitable'][i] = 'CND'\n",
    "\n",
    "# print(planets, len(planets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995ac88",
   "metadata": {},
   "source": [
    "### Comparing our data to PHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b57421",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_planets = pd.read_csv('../data/habitable-planets.csv')['pl_name'].to_numpy()\n",
    "phl_planets = pd.read_csv('../data/PHL-dataset-simplified.csv')['pl_name'].to_numpy()\n",
    "\n",
    "np.sort(our_planets)\n",
    "np.sort(phl_planets)\n",
    "\n",
    "print(our_planets)\n",
    "print(phl_planets)\n",
    "\n",
    "# stringVal = \"HD\"\n",
    "# our_planets = [\n",
    "#     our_planet for our_planet in our_planets if stringVal not in our_planet]\n",
    "\n",
    "# print(our_planets)\n",
    "\n",
    "num_similar_planets = 0\n",
    "\n",
    "for our_planet in our_planets:\n",
    "    our_planet = our_planet[:-2]\n",
    "\n",
    "    for phl_planet in phl_planets:\n",
    "        phl_planet = phl_planet[:-2]\n",
    "        if (our_planet == phl_planet):\n",
    "            num_similar_planets += 1\n",
    "\n",
    "print(num_similar_planets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a524a2b0",
   "metadata": {},
   "source": [
    "## Visualizing our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15522b0a",
   "metadata": {},
   "source": [
    "### Percent of Controversial Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5594a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_pl_flag_0 = controv_flags_col.value_counts()[0]\n",
    "num_pl_flag_1 = controv_flags_col.value_counts()[1]\n",
    "\n",
    "nums = [num_pl_flag_0, num_pl_flag_1]\n",
    "labels = [\"Flag of 0\", \"Flag of 1\"]\n",
    "\n",
    "explode = (0.1, 0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.pie(nums, labels=labels,autopct='%1.2f%%',explode=explode, pctdistance=1.1, labeldistance=1.3)\n",
    "plt.title('Percent of Controversial Flags in NASA Exoplanet Archive',size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54b16a",
   "metadata": {},
   "source": [
    "### Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a09bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicates = planet_names.duplicated().sum()\n",
    "total_planets = len(planet_names)\n",
    "num_not_duplicated = total_planets - num_duplicates\n",
    "\n",
    "labels = ['Duplicates', 'Not Duplicates']\n",
    "pcnt_duplicates = num_duplicates / total_planets\n",
    "pcnt_non_duplicates = num_not_duplicated / total_planets\n",
    "\n",
    "sizes = [pcnt_duplicates, pcnt_non_duplicates]\n",
    "explode = (0.1, 0)\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "ax1.pie(sizes, labels=labels, explode=explode, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc842f3",
   "metadata": {},
   "source": [
    "### Pie Chart of Habitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a413510",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [61, 2417, 2552]\n",
    "labels = ['Habitable', 'Not Habitable', 'CND']\n",
    "explode=[0.4,0,0]\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.pie(nums, labels=labels,pctdistance=0.9,explode=explode)\n",
    "plt.title('Habitability of Exoplanets in NASA Exoplanet Archive',size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b12eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[df['Habitable']=='Yes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b572c",
   "metadata": {},
   "source": [
    "### Histogram of Eccentricity Values of Habitable Exoplanets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0,1,11)\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.hist(df2['pl_orbeccen'],bins=bins,ec='black')\n",
    "plt.xticks(ticks=bins)\n",
    "plt.title('Eccentricity Values of Habitable Exoplanets')\n",
    "plt.xlabel('Eccentricity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333f03db",
   "metadata": {},
   "source": [
    "### Histogram of Orbital Period Values of Habitable Exoplanets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f93e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "bins = np.linspace(0,2500,21)\n",
    "plt.hist(df2['pl_orbper'],bins=bins,ec='black')\n",
    "plt.title('Orbital Period Values of Habitable Exoplanets')\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Orbital Period (Days)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec70ec3",
   "metadata": {},
   "source": [
    "### Histogram of Semi-Major Axis Values of Habitable Exoplanets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca2748b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "bins=np.linspace(0,7,8)\n",
    "plt.hist(df2['pl_orbsmax'],bins=bins,ec='black')\n",
    "plt.title('Semi-Major Axis Values of Habitable Exoplanets')\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Semi-Major Axis (AU)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82124547",
   "metadata": {},
   "outputs": [],
   "source": [
    "planets_to_be_determined = df[\"Habitable\"]\n",
    "planets_to_be_determined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20db085f",
   "metadata": {},
   "source": [
    "### Comparing our Data to PHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc396329",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'habitable-planets.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m our_planets \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhabitable-planets.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpl_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      2\u001b[0m phl_planets \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPHL-dataset-simplified.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpl_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39msort(our_planets)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'habitable-planets.csv'"
     ]
    }
   ],
   "source": [
    "our_planets = pd.read_csv('habitable-planets.csv')['pl_name'].to_numpy()\n",
    "phl_planets = pd.read_csv('PHL-dataset-simplified.csv')['pl_name'].to_numpy()\n",
    "\n",
    "np.sort(our_planets)\n",
    "np.sort(phl_planets)\n",
    "\n",
    "print(our_planets)\n",
    "print(phl_planets)\n",
    "\n",
    "# stringVal = \"HD\"\n",
    "# our_planets = [\n",
    "#     our_planet for our_planet in our_planets if stringVal not in our_planet]\n",
    "\n",
    "# print(our_planets)\n",
    "\n",
    "num_similar_planets = 0\n",
    "\n",
    "for our_planet in our_planets:\n",
    "    our_planet = our_planet[:-2]\n",
    "\n",
    "    for phl_planet in phl_planets:\n",
    "        phl_planet = phl_planet[:-2]\n",
    "        if (our_planet == phl_planet):\n",
    "            num_similar_planets += 1\n",
    "\n",
    "print(num_similar_planets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9707c5a6",
   "metadata": {},
   "source": [
    "## Exporting our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bb429",
   "metadata": {},
   "outputs": [],
   "source": [
    "for planet in planets:\n",
    "    print(planet)\n",
    "\n",
    "with open('../data/habitable-planets.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['number', 'pl_name']\n",
    "    planet_count = 0\n",
    "\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for planet in planets:\n",
    "        planet_count += 1\n",
    "        writer.writerow({'number': planet_count, 'pl_name': planet})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d688df3862cb7e85a9e692ebc641fab133609ea0665f4b4b1480645ecc056e29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
